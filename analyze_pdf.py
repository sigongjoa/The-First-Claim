#!/usr/bin/env python3
import pdfplumber
import json
import os

pdf_path = "/mnt/d/progress/The-First-Claim/assets/1994037951_6WETqkrB_501827919862976725634521800816b5a957c592.pdf"

def analyze_pdf(pdf_file):
    """PDF íŒŒì¼ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    results = {
        "file_name": os.path.basename(pdf_file),
        "total_pages": 0,
        "text_content": [],
        "tables": [],
        "metadata": {},
        "summary": {}
    }

    try:
        with pdfplumber.open(pdf_file) as pdf:
            results["total_pages"] = len(pdf.pages)
            results["metadata"] = pdf.metadata

            print(f"ğŸ“„ PDF ë¶„ì„ ì‹œì‘: {os.path.basename(pdf_file)}")
            print(f"ğŸ“Š ì´ í˜ì´ì§€ ìˆ˜: {results['total_pages']}")
            print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°: {json.dumps(results['metadata'], indent=2, ensure_ascii=False)}")
            print("\n" + "="*80 + "\n")

            # ê° í˜ì´ì§€ ì²˜ë¦¬
            for page_num, page in enumerate(pdf.pages, 1):
                print(f"ğŸ“„ í˜ì´ì§€ {page_num}/{results['total_pages']} ë¶„ì„ ì¤‘...")

                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = page.extract_text()
                if text:
                    results["text_content"].append({
                        "page": page_num,
                        "text": text.strip()
                    })

                # í‘œ ì¶”ì¶œ
                tables = page.extract_tables()
                if tables:
                    for table_idx, table in enumerate(tables):
                        results["tables"].append({
                            "page": page_num,
                            "table_index": table_idx,
                            "data": table
                        })
                        print(f"   âœ“ í˜ì´ì§€ {page_num}ì—ì„œ í‘œ {table_idx + 1} ì°¾ìŒ")

            # ìš”ì•½ í†µê³„
            results["summary"] = {
                "total_pages": results["total_pages"],
                "total_text_blocks": len(results["text_content"]),
                "total_tables": len(results["tables"]),
                "has_metadata": bool(results["metadata"])
            }

            print("\n" + "="*80)
            print("ğŸ“Š ë¶„ì„ ì™„ë£Œ!")
            print(f"âœ“ ì´ í˜ì´ì§€: {results['summary']['total_pages']}")
            print(f"âœ“ í…ìŠ¤íŠ¸ ë¸”ë¡: {results['summary']['total_text_blocks']}")
            print(f"âœ“ í‘œ ê°œìˆ˜: {results['summary']['total_tables']}")
            print("="*80 + "\n")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        results["error"] = str(e)

    return results

def print_text_preview(results, max_length=500):
    """í…ìŠ¤íŠ¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"""
    if results["text_content"]:
        print("\nğŸ“ í…ìŠ¤íŠ¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:")
        print("="*80)
        for item in results["text_content"][:5]:  # ì²˜ìŒ 5ê°œ í˜ì´ì§€ë§Œ
            text = item["text"][:max_length]
            print(f"\n[í˜ì´ì§€ {item['page']}]")
            print(text)
            if len(item["text"]) > max_length:
                print(f"... (ë” ë§ì€ ë‚´ìš© ìˆìŒ, ì´ {len(item['text'])} ì)")

def print_tables_preview(results):
    """í‘œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"""
    if results["tables"]:
        print("\n\nğŸ“‹ í‘œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:")
        print("="*80)
        for item in results["tables"][:3]:  # ì²˜ìŒ 3ê°œ í‘œë§Œ
            print(f"\n[í˜ì´ì§€ {item['page']}, í‘œ {item['table_index'] + 1}]")
            table = item["data"]
            for row_idx, row in enumerate(table[:5]):  # ì²˜ìŒ 5ê°œ í–‰ë§Œ
                print(f"  í–‰ {row_idx + 1}: {row}")
            if len(table) > 5:
                print(f"  ... (ë” ë§ì€ í–‰ ìˆìŒ, ì´ {len(table)} í–‰)")

if __name__ == "__main__":
    results = analyze_pdf(pdf_path)
    print_text_preview(results)
    print_tables_preview(results)

    # ì „ì²´ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    output_file = "/mnt/d/progress/The-First-Claim/pdf_analysis_result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ ê²°ê³¼ ì •ë¦¬
        json_results = {
            "file_name": results["file_name"],
            "total_pages": results["total_pages"],
            "metadata": results["metadata"],
            "summary": results["summary"],
            "text_content_summary": [
                {
                    "page": item["page"],
                    "text_length": len(item["text"]),
                    "preview": item["text"][:200] + "..." if len(item["text"]) > 200 else item["text"]
                }
                for item in results["text_content"]
            ],
            "tables_summary": [
                {
                    "page": item["page"],
                    "table_index": item["table_index"],
                    "rows": len(item["data"]),
                    "columns": len(item["data"][0]) if item["data"] else 0
                }
                for item in results["tables"]
            ]
        }
        json.dump(json_results, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")
