# Project: OVERRIDE - Configuration Example
# Copy this file to .env and modify values as needed

# ============================================================================
# DEBUG & ENVIRONMENT
# ============================================================================

DEBUG=false
SERVER_ENVIRONMENT=development

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================

SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# SQLite session database path
DB_PATH=data/sessions.db

# Session TTL in seconds (default: 3600 = 1 hour)
SESSION_TTL=3600

# ============================================================================
# OLLAMA LLM CONFIGURATION
# ============================================================================

# Ollama API endpoint
OLLAMA_BASE_URL=http://localhost:11434

# Model names (must be pulled in Ollama first)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_GENERATION_MODEL=mistral

# ============================================================================
# EVALUATION ENGINE CONFIGURATION
# ============================================================================

# Novelty Evaluation
# Jaccard similarity threshold (0.0-1.0)
EVAL_NOVELTY_THRESHOLD=0.7

# Number of RAG results to retrieve
EVAL_RAG_TOP_K=5

# LLM Configuration
EVAL_LLM_MODEL=mistral

# Timeout for complete evaluation (seconds)
EVAL_TIMEOUT=5

# Enable/Disable evaluation stages
EVAL_ENABLE_LLM=true
EVAL_ENABLE_RAG=true

# Debug mode for evaluation
EVAL_DEBUG=false

# ============================================================================
# NOTES
# ============================================================================
#
# 1. Before running, make sure Ollama is running:
#    ollama serve
#
# 2. Pull required models:
#    ollama pull nomic-embed-text
#    ollama pull mistral
#
# 3. For production, set:
#    SERVER_ENVIRONMENT=production
#    DEBUG=false
#
# 4. Evaluation configuration can be fine-tuned:
#    - Lower EVAL_NOVELTY_THRESHOLD = more permissive novelty checks
#    - Higher EVAL_RAG_TOP_K = more context for LLM (slower)
#    - Longer EVAL_TIMEOUT = allow more complex evaluations
#
